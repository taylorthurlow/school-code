{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22688 images belonging to 2 classes.\n",
      "Found 5672 images belonging to 2 classes.\n",
      "Epoch 1/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.5792 - acc: 0.7371 - val_loss: 0.5740 - val_acc: 0.7353\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.57398, saving model to best.h5\n",
      "Epoch 2/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.5643 - acc: 0.7395 - val_loss: 0.5472 - val_acc: 0.7362\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.57398 to 0.54724, saving model to best.h5\n",
      "Epoch 3/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.5408 - acc: 0.7461 - val_loss: 0.5196 - val_acc: 0.7523\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.54724 to 0.51964, saving model to best.h5\n",
      "Epoch 4/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.5220 - acc: 0.7608 - val_loss: 0.4948 - val_acc: 0.7709\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.51964 to 0.49478, saving model to best.h5\n",
      "Epoch 5/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.4998 - acc: 0.7712 - val_loss: 0.4772 - val_acc: 0.7804\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.49478 to 0.47721, saving model to best.h5\n",
      "Epoch 6/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.4824 - acc: 0.7829 - val_loss: 0.4515 - val_acc: 0.8016\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47721 to 0.45152, saving model to best.h5\n",
      "Epoch 7/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.4595 - acc: 0.7973 - val_loss: 0.4238 - val_acc: 0.8151\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.45152 to 0.42384, saving model to best.h5\n",
      "Epoch 8/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.4328 - acc: 0.8156 - val_loss: 0.4063 - val_acc: 0.8257\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.42384 to 0.40632, saving model to best.h5\n",
      "Epoch 9/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.4076 - acc: 0.8296 - val_loss: 0.3701 - val_acc: 0.8513\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.40632 to 0.37013, saving model to best.h5\n",
      "Epoch 10/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.3792 - acc: 0.8444 - val_loss: 0.3350 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.37013 to 0.33500, saving model to best.h5\n",
      "Epoch 11/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.3568 - acc: 0.8568 - val_loss: 0.3347 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.33500 to 0.33469, saving model to best.h5\n",
      "Epoch 12/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.3400 - acc: 0.8622 - val_loss: 0.3101 - val_acc: 0.8796\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33469 to 0.31008, saving model to best.h5\n",
      "Epoch 13/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.3242 - acc: 0.8742 - val_loss: 0.3017 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.31008 to 0.30168, saving model to best.h5\n",
      "Epoch 14/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.3111 - acc: 0.8772 - val_loss: 0.3045 - val_acc: 0.8787\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.30168\n",
      "Epoch 15/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.3052 - acc: 0.8804 - val_loss: 0.2796 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.30168 to 0.27959, saving model to best.h5\n",
      "Epoch 16/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.2944 - acc: 0.8849 - val_loss: 0.2751 - val_acc: 0.8937\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27959 to 0.27514, saving model to best.h5\n",
      "Epoch 17/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2846 - acc: 0.8906 - val_loss: 0.2732 - val_acc: 0.8960\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.27514 to 0.27324, saving model to best.h5\n",
      "Epoch 18/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.2789 - acc: 0.8917 - val_loss: 0.2524 - val_acc: 0.9021\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.27324 to 0.25244, saving model to best.h5\n",
      "Epoch 19/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.2699 - acc: 0.8973 - val_loss: 0.2578 - val_acc: 0.9033\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.25244\n",
      "Epoch 20/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.2654 - acc: 0.8980 - val_loss: 0.2508 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.25244 to 0.25080, saving model to best.h5\n",
      "Epoch 21/200\n",
      "1418/1418 [==============================] - 109s 77ms/step - loss: 0.2604 - acc: 0.9019 - val_loss: 0.2451 - val_acc: 0.9049\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.25080 to 0.24513, saving model to best.h5\n",
      "Epoch 22/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2537 - acc: 0.9030 - val_loss: 0.2444 - val_acc: 0.9114\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.24513 to 0.24440, saving model to best.h5\n",
      "Epoch 23/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2526 - acc: 0.9034 - val_loss: 0.2349 - val_acc: 0.9118\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.24440 to 0.23487, saving model to best.h5\n",
      "Epoch 24/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2441 - acc: 0.9073 - val_loss: 0.2523 - val_acc: 0.9013\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.23487\n",
      "Epoch 25/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2444 - acc: 0.9068 - val_loss: 0.2382 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.23487\n",
      "Epoch 26/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2384 - acc: 0.9107 - val_loss: 0.2206 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.23487 to 0.22062, saving model to best.h5\n",
      "Epoch 27/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2325 - acc: 0.9117 - val_loss: 0.2360 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.22062\n",
      "Epoch 28/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2298 - acc: 0.9129 - val_loss: 0.2214 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.22062\n",
      "Epoch 29/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2251 - acc: 0.9146 - val_loss: 0.2115 - val_acc: 0.9247\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.22062 to 0.21153, saving model to best.h5\n",
      "Epoch 30/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2232 - acc: 0.9165 - val_loss: 0.2107 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.21153 to 0.21074, saving model to best.h5\n",
      "Epoch 31/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2215 - acc: 0.9192 - val_loss: 0.2165 - val_acc: 0.9194\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.21074\n",
      "Epoch 32/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2192 - acc: 0.9181 - val_loss: 0.2198 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.21074\n",
      "Epoch 33/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2167 - acc: 0.9201 - val_loss: 0.2237 - val_acc: 0.9180\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.21074\n",
      "Epoch 34/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2130 - acc: 0.9213 - val_loss: 0.2197 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.21074\n",
      "Epoch 35/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2112 - acc: 0.9214 - val_loss: 0.2260 - val_acc: 0.9187\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.21074\n",
      "Epoch 36/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2096 - acc: 0.9229 - val_loss: 0.2399 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.21074\n",
      "Epoch 37/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2085 - acc: 0.9232 - val_loss: 0.2164 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.21074\n",
      "Epoch 38/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2059 - acc: 0.9252 - val_loss: 0.2107 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.21074\n",
      "Epoch 39/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.2060 - acc: 0.9252 - val_loss: 0.2046 - val_acc: 0.9226\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.21074 to 0.20455, saving model to best.h5\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1418/1418 [==============================] - 107s 76ms/step - loss: 0.2007 - acc: 0.9261 - val_loss: 0.2140 - val_acc: 0.9220\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.20455\n",
      "Epoch 41/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1995 - acc: 0.9264 - val_loss: 0.2085 - val_acc: 0.9243\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.20455\n",
      "Epoch 42/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1972 - acc: 0.9276 - val_loss: 0.2033 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.20455 to 0.20333, saving model to best.h5\n",
      "Epoch 43/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1953 - acc: 0.9289 - val_loss: 0.1936 - val_acc: 0.9310\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.20333 to 0.19355, saving model to best.h5\n",
      "Epoch 44/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1961 - acc: 0.9280 - val_loss: 0.2095 - val_acc: 0.9261\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.19355\n",
      "Epoch 45/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1922 - acc: 0.9308 - val_loss: 0.2025 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.19355\n",
      "Epoch 46/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1909 - acc: 0.9301 - val_loss: 0.2007 - val_acc: 0.9252\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.19355\n",
      "Epoch 47/200\n",
      "1418/1418 [==============================] - 107s 76ms/step - loss: 0.1884 - acc: 0.9319 - val_loss: 0.2058 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.19355\n",
      "Epoch 48/200\n",
      "1418/1418 [==============================] - 107s 76ms/step - loss: 0.1875 - acc: 0.9321 - val_loss: 0.1936 - val_acc: 0.9316\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.19355\n",
      "Epoch 49/200\n",
      "1418/1418 [==============================] - 107s 76ms/step - loss: 0.1863 - acc: 0.9327 - val_loss: 0.1985 - val_acc: 0.9286\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.19355\n",
      "Epoch 50/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1852 - acc: 0.9337 - val_loss: 0.1923 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.19355 to 0.19227, saving model to best.h5\n",
      "Epoch 51/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1871 - acc: 0.9330 - val_loss: 0.2029 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.19227\n",
      "Epoch 52/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1849 - acc: 0.9352 - val_loss: 0.1910 - val_acc: 0.9337\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.19227 to 0.19099, saving model to best.h5\n",
      "Epoch 53/200\n",
      "1418/1418 [==============================] - 107s 76ms/step - loss: 0.1836 - acc: 0.9314 - val_loss: 0.1955 - val_acc: 0.9303\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.19099\n",
      "Epoch 54/200\n",
      "1418/1418 [==============================] - 107s 76ms/step - loss: 0.1806 - acc: 0.9350 - val_loss: 0.1865 - val_acc: 0.9341\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.19099 to 0.18653, saving model to best.h5\n",
      "Epoch 55/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1781 - acc: 0.9359 - val_loss: 0.1928 - val_acc: 0.9339\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.18653\n",
      "Epoch 56/200\n",
      "1418/1418 [==============================] - 107s 76ms/step - loss: 0.1806 - acc: 0.9360 - val_loss: 0.1883 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.18653\n",
      "Epoch 57/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1800 - acc: 0.9342 - val_loss: 0.1966 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.18653\n",
      "Epoch 58/200\n",
      "1418/1418 [==============================] - 107s 76ms/step - loss: 0.1742 - acc: 0.9379 - val_loss: 0.1825 - val_acc: 0.9358\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.18653 to 0.18253, saving model to best.h5\n",
      "Epoch 59/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1749 - acc: 0.9373 - val_loss: 0.1920 - val_acc: 0.9349\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.18253\n",
      "Epoch 60/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1745 - acc: 0.9364 - val_loss: 0.1777 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.18253 to 0.17774, saving model to best.h5\n",
      "Epoch 61/200\n",
      "1418/1418 [==============================] - 107s 76ms/step - loss: 0.1735 - acc: 0.9370 - val_loss: 0.1959 - val_acc: 0.9314\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.17774\n",
      "Epoch 62/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1731 - acc: 0.9380 - val_loss: 0.1847 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.17774\n",
      "Epoch 63/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1678 - acc: 0.9400 - val_loss: 0.2015 - val_acc: 0.9309\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.17774\n",
      "Epoch 64/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1692 - acc: 0.9410 - val_loss: 0.1820 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.17774\n",
      "Epoch 65/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1668 - acc: 0.9419 - val_loss: 0.1851 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.17774\n",
      "Epoch 66/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1682 - acc: 0.9402 - val_loss: 0.1933 - val_acc: 0.9316\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.17774\n",
      "Epoch 67/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1685 - acc: 0.9404 - val_loss: 0.1902 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.17774\n",
      "Epoch 68/200\n",
      "1418/1418 [==============================] - 107s 76ms/step - loss: 0.1640 - acc: 0.9422 - val_loss: 0.1798 - val_acc: 0.9383\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.17774\n",
      "Epoch 69/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1628 - acc: 0.9433 - val_loss: 0.1942 - val_acc: 0.9323\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.17774\n",
      "Epoch 70/200\n",
      "1418/1418 [==============================] - 108s 76ms/step - loss: 0.1671 - acc: 0.9412 - val_loss: 0.2011 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.17774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bfbb03710>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "# Set the desired dimension of our input images, images will be resized\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# Set the location of our input data\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "\n",
    "# Use as much of our data as possible, must be a multiple of our batch size\n",
    "nb_train_samples = 16 * 1418\n",
    "nb_validation_samples = 16 * 354\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "\n",
    "# Determine shape of images based on current backend\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "# Construct our model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# Set up a couple different options for optimizers\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "rmsprop = optimizers.RMSprop(lr=0.0005, rho=0.9, epsilon=None, decay=0.0)\n",
    "sgd = optimizers. SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "# Compile our model with one of the aforementioned optimizers\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Augment our input data by generating new images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    height_shift_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Only augment our test images by resizing them\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Set up our training data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Set up our validation data generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Save the best model if applicable after each epoch\n",
    "save_each_callback = ModelCheckpoint('best.h5', monitor='val_loss', verbose=1,\n",
    "                                     save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "# Stop early if validation loss doesn't improve for N consecutive epochs\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# Start training\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size,\n",
    "    callbacks=[save_each_callback, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# Set the desired dimension of our input images, images will be resized\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# Load the best model from the training session\n",
    "model = load_model('best.h5')\n",
    "\n",
    "# Set the location of our input data\n",
    "test_image_directory = 'data/test'\n",
    "\n",
    "# Set up a sort method which does \"natural sorting\", this way filenames are\n",
    "# sorted \"1, 2, 3... 10\" instead of \"1, 10, 11... 2, 21, 22...\"\n",
    "def natural_sort_key(s, _nsre=re.compile('([0-9]+)')):\n",
    "    return [int(text) if text.isdigit() else text.lower()\n",
    "        for text in _nsre.split(s)]\n",
    "\n",
    "# Iterate over all the test images with the aforementioned natural sort method\n",
    "# and construct an array from the image, add it to an array of images\n",
    "images_array = []\n",
    "for file in sorted(os.listdir(test_image_directory), key=natural_sort_key):\n",
    "\tif file.endswith('.jpg'):\n",
    "\t\timage_path = test_image_directory + '/' + file\n",
    "\t\timage = load_img(image_path, False, target_size=(img_width, img_height))\n",
    "\t\timage = img_to_array(image)\n",
    "\t\timage = image / 255\n",
    "\t\timages_array.append(image)\n",
    "\n",
    "# Perform predictions based on each element in the images array and save the results\n",
    "images = np.stack(images_array)\n",
    "predictions = model.predict(images).flatten()\n",
    "np.savetxt('results.txt', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Parse the results file, which contains one number per line in scientific\n",
    "# notation, format the number to the proper precision float, and write it\n",
    "# to a new file in CSV format for submission to Kaggle\n",
    "with open('results.csv', 'w', newline='') as destination:\n",
    "    writer = csv.writer(destination, delimiter=',')\n",
    "    writer.writerow(['Id', 'Expected'])\n",
    "    with open('results.txt', 'r') as source:\n",
    "        i = 0\n",
    "        for line in source:\n",
    "            i += 1\n",
    "            value = float(line)\n",
    "            writer.writerow([f'test_{i}.jpg', round(value, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
